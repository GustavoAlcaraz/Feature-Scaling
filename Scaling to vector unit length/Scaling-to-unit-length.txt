Scaling to vector unit length / unit norm

In this procedure we scale the components of a feature vector such that the complete vector has a 
length of 1 or, in other words a norm of 1. Note that this normalisation procedure normalises the 
feature vector, and not the observation vector. So we divide by the norm of the feature vector, 
observation per observation, across the different variables, and not by the norm of the observation 
vector, across observations for the same feature.

First, let me give you the formulas, and then I illustrate with an example.

Scaling to unit norm, formulas
Scaling to unit norm is achieved by dividing each feature vector by either the Manhattan distance 
(l1 norm) or the Euclidean distance of the vector (l2 norm):

X_scaled_l1 = X / l1(X)

X_scaled_l2 = X / l2(X)

The Manhattan distance is given by the sum of the absolute components of the vector:

l1(X) = |x1| + |x2| + ... + |xn|

Whereas the Euclidean distance is given by the square root of the square sum of the component of 
the vector:

l2(X) = sqr( x1^2 + x2^2 + ... + xn^2 )

In the above example, x1 is variable 1, x2 variable 2, and xn variable n, and X is the data for 1 
observation across variables (a row in other words).

Note as well that as the euclidean distance squares the values of the feature vector components, 
outliers have a heavier weight. With outliers, we may prefer to use l1 normalisation.

Scaling to unit norm, examples
For example, if our data has 1 observations (1 row) and 3 variables:

number of pets
number of children
age
The values for each variable for that single observation are 10, 15 and 20. Our vector 
X = [10, 15, 20]. Then:

l1(X) = 10 + 15 + 20 = 45

l2(X) = sqr( 10^2 + 15^2 + 20^2) = sqr( 100 + 225 + 400) = 26.9

The euclidean distance is always smaller than the manhattan distance.

The normalised vector values are therefore:

X_scaled_l1 = [ 10/45, 15/45, 20/45 ] = [0.22, 0.33, 0.44]

X_scaled_l2 = [10/26.9, 15/26.9, 20/26.9 ] = [0.37, 0.55, 0.74]

Scikit-learn recommends this scaling procedures for text classification or clustering. 
For example, they quote the dot product of two l2-normalized TF-IDF vectors is the cosine 
similarity of the vectors and is the base similarity metric for the Vector Space Model commonly 
used by the Information Retrieval community.

In this demo
We will perform scaling to unit length using Scikit-learn